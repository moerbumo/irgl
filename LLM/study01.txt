1. RAG（検索拡張生成）とは
大規模言語モデル（LLM）に、外部の知識ソースから関連情報を検索（Retrieval）する能力を付与し、その情報に基づいて回答を生成（Generation）させる技術。
LLM単体よりも、より正確で、最新の情報に基づいた回答が可能になる。

2. 幻覚（ハルシネーション）とは
LLMが、事実に基づかない、もっともらしいが不正確な情報を生成してしまう現象。
LLM会产生基于事实、看似合理但并不准确的信息的现象。
学習データに含まれない情報や、曖昧な質問に対して発生しやすい。

3. RAGによるハルシネーションの改善について
RAGは、回答生成前に、信頼できる知識ソース（例：社内Wiki）から関連情報を検索し、その情報を根拠（Grounding）として利用する。
これにより、LLMが事実に基づかずに回答を創作する「幻覚」を大幅に抑制し、回答の信頼性を向上させる。

4. 外部API（バックログを例に）をRAGの情報源とする場合の考え方・進め方
実現可能性: BacklogのWikiのような社内知識ベースは、RAGの知識源として活用可能。
考え方:
APIを利用してWikiデータを定期的に取得する。
取得したデータを、検索に適した形式（ベクトルデータなど）に変換・保存する（ベクトルDB）。
ユーザーの質問に応じて、ベクトルDBから関連情報を検索し、LLMにコンテキストとして提供する。
進め方:
Backlog APIの仕様を確認し、データ取得方法を確立する。
データの前処理、ベクトル化、ベクトルDBへの格納パイプラインを構築する。
LLMと連携し、検索結果をプロンプトに組み込む仕組みを実装する。
定期的なデータ更新戦略（全量 or 差分）を検討・実装する。